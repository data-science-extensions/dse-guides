{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c329859",
   "metadata": {},
   "source": [
    "# Handling Missing Time Series Data\n",
    "\n",
    "<style>\n",
    "    table td {\n",
    "        vertical-align: middle;\n",
    "        position: relative;\n",
    "    }\n",
    "    table td p {\n",
    "        display: inline-block;\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "    .center {\n",
    "        text-align: center;\n",
    "    }\n",
    "    .justify {\n",
    "        display: flex;\n",
    "        justify-content: space-between;\n",
    "        align-items: center;\n",
    "    }\n",
    "    .green {\n",
    "        background-color: rgba(144, 238, 144, 0.2);\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0710e45",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690b34f",
   "metadata": {},
   "source": [
    "## Causes / Reasons\n",
    "\n",
    "Some examples:\n",
    "\n",
    "| <div class=\"center\">Reason</div> | <div class=\"center\">Comment</div>                                                           | <div class=\"center\">Score</div>                                                     |\n",
    "| -------------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "|                                  |                                                                                             | <div class=\"justify\"><span>Random</span><span>-</span><span>Systematic</span></div> |\n",
    "| Sensor failure                   | Data could not be retrieved or kept                                                         | <table><tr><td>⬜</td><td>⬜</td><td>❎</td><td>⬜</td><td>⬜</td></tr></table>          |\n",
    "| Not applicable                   | If not children, there is no age of your children                                           | <table><tr><td>⬜</td><td>⬜</td><td>⬜</td><td>⬜</td><td>❎</td></tr></table>          |\n",
    "| Publication lag                  | Sydney market volumes always come 3 months delayed because of complicated gathering process | <table><tr><td>❎</td><td>⬜</td><td>⬜</td><td>⬜</td><td>⬜</td></tr></table>          |\n",
    "| Drop in/out                      | Categories (dis)appeared at some point in time                                              | <table><tr><td>⬜</td><td>⬜</td><td>⬜</td><td>⬜</td><td>❎</td></tr></table>          |\n",
    "| Label change                     | Split of a category in to two                                                               | <table><tr><td>⬜</td><td>⬜</td><td>⬜</td><td>⬜</td><td>❎</td></tr></table>          |\n",
    "| Intentional                      | Intentionally filtered outlier (wrong data suspect)                                         | <table><tr><td>⬜</td><td>⬜</td><td>❎</td><td>⬜</td><td>⬜</td></tr></table>          |\n",
    "| Refusal                          | Optional data not provided or refused to answer                                             | <table><tr><td>⬜</td><td>⬜</td><td>⬜</td><td>❎</td><td>⬜</td></tr></table>          |\n",
    "| Table joins                      | Missing data is generated by table joins in SQL                                             | <table><tr><td>⬜</td><td>⬜</td><td>⬜</td><td>❎</td><td>⬜</td></tr></table>          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2a830",
   "metadata": {},
   "source": [
    "### Missing Completely at Random (MCAR)\n",
    "\n",
    "Mechanisms/examples:\n",
    "\n",
    "- Reporting lag of last 3 months\n",
    "- Our pipeline crashed because of unrelated reasons\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td class=\"center\">\n",
    "            Completely<br>random<br>➡️\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>&nbsp;</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>&nbsp;</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96e4c7",
   "metadata": {},
   "source": [
    "### Missing at Random (MAR)\n",
    "\n",
    "Mechanisms/examples:\n",
    "\n",
    "- Airlines have a different level of 'completeness' of flight event data\n",
    "- Older trucks are not yet all equipped with GPS sensors (correlation with capacity, CO2 emissions, etc)\n",
    "- Shipment not detected as arrived because truck GPS did not hit the geofence properly (location specific problem)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">y-values above<br>10.0 have a 50%<br>chance of not<br>being reported<br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1987ca",
   "metadata": {},
   "source": [
    "### Missing Not at Random (MNAR)\n",
    "\n",
    "Mechanisms/examples:\n",
    "\n",
    "- Old vessel schedules are purged in shipping systems if they have no corresponding shipment.\n",
    "- Not all airlines deliver US flight events.\n",
    "- An arrival even in Sydney airport is missing if it arrived at a nearby airport and was trucked to Sydney (road feeder service), plus the suspected handling time is longer in this situation.\n",
    "- Dates with no volume will be missed in SQL GROUP BY query result.\n",
    "- Unfinished shipments have no delivery date.\n",
    "- Shipment rate index is missing in Chinese New Year week.\n",
    "- GPS sensor turns off when truck is not moving.\n",
    "- GPS sensor turns off when truck is in tunnel.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Some system<br>issues causes<br>values above 11.0<br>to not be reported<br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c002e",
   "metadata": {},
   "source": [
    "### Set up\n",
    "\n",
    "Before we begin, it is necessary to set up our environment and create a sample data set with missing values. Click on \"Show code\" to see the full code for all sections on this page. Click \"No code\" at any time to hide the code.\n",
    "\n",
    "### No code\n",
    "\n",
    "### Show code\n",
    "\n",
    "For this guide, we will use a number of libraries to show the functionality. The important ones are:\n",
    "\n",
    "- [`numpy`][`numpy`] and [`pandas`][`pandas`] for data manipulation\n",
    "- [`synthetic_data_generators`][`synthetic_data_generators`] to create sample time series data\n",
    "- [`plotly`][`plotly`] for visualisation\n",
    "- [`pmdarima`][`pmdarima`] for ARIMA modelling\n",
    "- [`sklearn`][`sklearn`] for machine learning models\n",
    "- [`tqdm`][`tqdm`] for progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StdLib Imports\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from typing import Literal\n",
    "\n",
    "# Third Party Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import PerformanceWarning\n",
    "from plotly import express as px, graph_objects as go, io as pio\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from synthetic_data_generators.time_series import TimeSeriesGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b04e6",
   "metadata": {},
   "source": [
    "After importing the necessary libraries, we can set up some global settings which will be used throughout the guide. This includes setting a random seed for reproducibility (`RANDOM_SEED`), defining the number of periods for our time series data (`NUM_PERIODS`), and configuring Plotly's default template for visualizations (`pio.templates.default`). We also instantiate the `TimeSeriesGenerator()` class, assigning a constant seed for reproducibility (`TSG`). Additionally, we will suppress certain warnings to keep the output clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab36a2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Constants, Settings, Instantiations\n",
    "RANDOM_SEED = 42\n",
    "NUM_PERIODS = 1096\n",
    "pio.templates.default = \"simple_white+gridon\"\n",
    "TSG = TimeSeriesGenerator(seed=RANDOM_SEED)\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4887a5a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In this guide, we will constantly be plotting our data to visualise the effects of missing data handling techniques. Therefore, we define a single helper function `plot_data()` that we can reuse for convenience and consistent formatting. It takes in a DataFrame and various parameters to create a line plot comparing the original data with missing values and the filled data. The function also allows for customization of titles, subtitles, output file saving, and whether to show or return the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a739c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(\n",
    "    data: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    missing_col: str,\n",
    "    fill_col: str,\n",
    "    title: str,\n",
    "    subtitle: str | None = None,\n",
    "    output_file: str | None = None,\n",
    "    show_or_return: Literal[\"show\", \"return\"] = \"show\",\n",
    ") -> go.Figure | None:\n",
    "    fig: go.Figure = (\n",
    "        px.line(title=f\"{title}<br><sup>{subtitle}</sup>\" if subtitle else title)\n",
    "        .add_scatter(\n",
    "            name=\"filled\",\n",
    "            x=data[date_col],\n",
    "            y=data[fill_col],\n",
    "            mode=\"lines+markers\",\n",
    "            line_color=\"crimson\",\n",
    "            line_width=1,\n",
    "            marker_size=4,\n",
    "        )\n",
    "        .add_scatter(\n",
    "            name=\"original\",\n",
    "            x=data[date_col],\n",
    "            y=data[missing_col],\n",
    "            mode=\"lines+markers\",\n",
    "            line_color=\"cornflowerblue\",\n",
    "        )\n",
    "        .update_layout(\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Value\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=1,\n",
    "                xanchor=\"left\",\n",
    "                x=0,\n",
    "                traceorder=\"reversed\",\n",
    "            ),\n",
    "            xaxis_range=[\n",
    "                data[date_col].min() - pd.offsets.Day(3),\n",
    "                data[date_col].max() + pd.offsets.Day(3),\n",
    "            ],\n",
    "            title=dict(\n",
    "                x=0.5,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"top\",\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if output_file:\n",
    "        fig.write_html(output_file, include_plotlyjs=\"cdn\")\n",
    "\n",
    "    if show_or_return == \"show\":\n",
    "        fig.show()\n",
    "    elif show_or_return == \"return\":\n",
    "        return fig\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid value for `show_or_return`: '{show_or_return}'. Must be either: 'show' or 'return'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e8876",
   "metadata": {},
   "source": [
    "Now that we have our environment set up, we can create a sample time series data set with missing values. We will generate seasonal data with a yearly seasonality pattern and then randomly remove 50% of the data points to simulate missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10801cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data parameters\n",
    "start_date = datetime(2023, 1, 1)\n",
    "NUM_PERIODS = 365\n",
    "interpolation_nodes: tuple[list[int], ...] = ([0, 160], [7, 160], [14, 160], [34, 160])\n",
    "level_breaks: list[list[int]] = []\n",
    "randomwalk_scale: float = 0\n",
    "season_eff: float = 0.7\n",
    "noise_scale: float = 15\n",
    "season_conf: dict[str, int | str] = {\n",
    "    \"style\": \"sin\",\n",
    "    \"period_length\": 28 * 6,\n",
    "    \"start_index\": 2,\n",
    "    \"amplitude\": 2,\n",
    "}\n",
    "\n",
    "# Build data set\n",
    "data: pd.DataFrame = (\n",
    "    TSG.create_time_series(\n",
    "        start_date=start_date,\n",
    "        n_periods=NUM_PERIODS,\n",
    "        interpolation_nodes=interpolation_nodes,\n",
    "        level_breaks=level_breaks,\n",
    "        randomwalk_scale=randomwalk_scale,\n",
    "        season_conf=season_conf,\n",
    "        season_eff=season_eff,\n",
    "        noise_scale=noise_scale,\n",
    "        seed=RANDOM_SEED,\n",
    "    )\n",
    "    .assign(\n",
    "        Missing=lambda df: np.where(\n",
    "            df.index.isin(\n",
    "                np.random.default_rng(seed=RANDOM_SEED).choice(\n",
    "                    df.index,\n",
    "                    size=len(df) // 2,\n",
    "                    replace=False,\n",
    "                )\n",
    "            ),\n",
    "            np.nan,\n",
    "            df[\"Value\"],\n",
    "        ),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68372543",
   "metadata": {},
   "source": [
    "When we inspect the generated data, we can see the number of missing values in the \"Missing\" column and a preview of the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3938f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print(data.isna().sum().to_frame(\"Num Missing\").to_markdown())\n",
    "print(data.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7356c38",
   "metadata": {},
   "source": [
    "|         | Missing Values |\n",
    "| :------ | -------------: |\n",
    "| index   |              0 |\n",
    "| Date    |              0 |\n",
    "| Value   |              0 |\n",
    "| Missing |            182 |\n",
    "\n",
    "|      | index               | Date                |   Value | Missing |\n",
    "| ---: | :------------------ | :------------------ | ------: | ------: |\n",
    "|    0 | 2023-01-01 00:00:00 | 2023-01-01 00:00:00 | 245.059 | 245.059 |\n",
    "|    1 | 2023-01-02 00:00:00 | 2023-01-02 00:00:00 | 196.839 | 196.839 |\n",
    "|    2 | 2023-01-03 00:00:00 | 2023-01-03 00:00:00 | 191.966 |     nan |\n",
    "|    3 | 2023-01-04 00:00:00 | 2023-01-04 00:00:00 | 208.287 | 208.287 |\n",
    "|    4 | 2023-01-05 00:00:00 | 2023-01-05 00:00:00 | 216.724 | 216.724 |\n",
    "|    5 | 2023-01-06 00:00:00 | 2023-01-06 00:00:00 | 197.463 | 197.463 |\n",
    "|    6 | 2023-01-07 00:00:00 | 2023-01-07 00:00:00 | 217.824 | 217.824 |\n",
    "|    7 | 2023-01-08 00:00:00 | 2023-01-08 00:00:00 | 205.426 | 205.426 |\n",
    "|    8 | 2023-01-09 00:00:00 | 2023-01-09 00:00:00 | 201.368 |     nan |\n",
    "|    9 | 2023-01-10 00:00:00 | 2023-01-10 00:00:00 | 192.668 |     nan |\n",
    "\n",
    "We can also visualise the data using our `plot_data()` function, which shows the seasonal pattern along with the missing data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plot_data(\n",
    "    data=data,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Value\",\n",
    "    title=\"Seasonal Data - With missing data points\",\n",
    "    subtitle=\"(using synthetic data)\",\n",
    "    output_file=\"./images/00_seasonal_data_with_missing.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e8860",
   "metadata": {},
   "source": [
    "As you can see with the below plot, the data exhibits a clear seasonal pattern, but there are several missing data points scattered throughout the time series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630ca4e",
   "metadata": {},
   "source": [
    "## Interpolation / Extrapolation\n",
    "\n",
    "Interpolation and extrapolation are techniques used to estimate missing values in a time series data set. Interpolation is used to fill in missing values within the range of existing data, while extrapolation is used to estimate values outside the range of existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f7a82",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "- Definition: there is always at least one value somewhere before and at least one somewhere after the missing value\n",
    "- Under certain assumptions (e.g. the true but unknown function is continuous or differentiable) it is mathematically proven that the interpolation gets better and better with increasing polynomial degree and density of known nodes (proven to converge)\n",
    "\n",
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6770ef",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": [1, 2, 3, 4, 5, 6],\n",
    "        \"all\": [1, 7.5, 5.5, 4.8, 5.5, 7],\n",
    "        \"missing\": [False, False, True, True, False, False],\n",
    "    },\n",
    ").assign(\n",
    "    value=lambda df: np.where(df[\"missing\"], np.nan, df[\"all\"]),\n",
    "    missing=lambda df: np.where(df[\"missing\"], df[\"all\"], np.nan),\n",
    ")\n",
    "\n",
    "fig = (\n",
    "    px.line()\n",
    "    .add_scatter(\n",
    "        x=dat[\"time\"],\n",
    "        y=dat[\"all\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"all\",\n",
    "        line=dict(shape=\"spline\", smoothing=1.3, color=\"teal\", width=3),\n",
    "    )\n",
    "    .add_scatter(\n",
    "        x=dat[\"time\"],\n",
    "        y=dat[\"value\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"value\",\n",
    "        marker=dict(color=\"teal\", size=50),\n",
    "    )\n",
    "    .add_scatter(\n",
    "        x=dat[\"time\"],\n",
    "        y=dat[\"missing\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"missing\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            color=\"lightgrey\",\n",
    "            size=50,\n",
    "            line=dict(\n",
    "                color=\"teal\",\n",
    "                width=2,\n",
    "                # dash=\"dash\",  #<-- feature request: plotly/plotly.py#5443\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    .add_annotation(\n",
    "        ax=3.4,\n",
    "        ay=2,\n",
    "        x=3,\n",
    "        y=5.5,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        axref=\"x\",\n",
    "        ayref=\"y\",\n",
    "        text=\"Missing Data\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor=\"grey\",\n",
    "        bgcolor=\"white\",\n",
    "        standoff=30,\n",
    "        startstandoff=10,\n",
    "    )\n",
    "    .add_annotation(\n",
    "        ax=3.4,\n",
    "        ay=2,\n",
    "        x=4,\n",
    "        y=4.8,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        axref=\"x\",\n",
    "        ayref=\"y\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor=\"grey\",\n",
    "        standoff=30,\n",
    "        startstandoff=15,\n",
    "    )\n",
    "    .add_annotation(\n",
    "        ax=6,\n",
    "        ay=7,\n",
    "        x=7,\n",
    "        y=9,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        axref=\"x\",\n",
    "        ayref=\"y\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=3,\n",
    "        arrowcolor=\"teal\",\n",
    "        startstandoff=25,\n",
    "    )\n",
    "    .update_layout(\n",
    "        showlegend=False,\n",
    "        xaxis=dict(showgrid=False, showticklabels=False, showline=False, ticks=\"\"),\n",
    "        yaxis=dict(showgrid=False, showticklabels=False, showline=False, ticks=\"\"),\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"./images/00_interpolation.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show(editable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2e7dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7e115d9",
   "metadata": {},
   "source": [
    "### Extrapolation\n",
    "\n",
    "- Definition: there is no other known node left or right of the missing value (example: typical forecast situation)\n",
    "- In this case it is not guaranteed that we can converge to the truth with more historical information or higher degree\n",
    "- In other words extrapolation is \"guessing\"\n",
    "- This is why trend extrapolation in forecasting is always a delicate/shaky thing and requires external assumptions on future trend behaviour\n",
    "\n",
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628627e4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": [1, 2, 3, 4, 5, 5],\n",
    "        \"all\": [1, 7.5, 5.5, 4.2, 5.5, 3],\n",
    "        \"missing\": [False, False, False, False, True, True],\n",
    "    },\n",
    ").assign(\n",
    "    value=lambda df: np.where(df[\"missing\"], np.nan, df[\"all\"]),\n",
    "    missing=lambda df: np.where(df[\"missing\"], df[\"all\"], np.nan),\n",
    ")\n",
    "\n",
    "fig = (\n",
    "    px.line()\n",
    "    .add_scatter(\n",
    "        x=list(dat[\"time\"][:5]) + [6],\n",
    "        y=list(dat[\"all\"][:5]) + [7.5],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"all\",\n",
    "        line=dict(shape=\"spline\", smoothing=1.3, color=\"teal\", width=3),\n",
    "        marker=dict(size=20, symbol=\"arrow-up\", angleref=\"previous\"),\n",
    "    )\n",
    "    .add_scatter(\n",
    "        x=[4, 5, 6],\n",
    "        y=[4.2, 3, 2.5],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"highlight\",\n",
    "        line=dict(shape=\"spline\", smoothing=1.3, color=\"teal\", width=3, dash=\"dash\"),\n",
    "        marker=dict(size=20, symbol=\"arrow-up\", angleref=\"previous\"),\n",
    "    )\n",
    "    .add_scatter(\n",
    "        x=dat[\"time\"],\n",
    "        y=dat[\"value\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"value\",\n",
    "        marker=dict(color=\"teal\", size=50),\n",
    "    )\n",
    "    .add_scatter(\n",
    "        x=dat[\"time\"],\n",
    "        y=dat[\"missing\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"missing\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            color=\"lightgrey\",\n",
    "            size=50,\n",
    "            line=dict(\n",
    "                color=\"teal\",\n",
    "                width=2,\n",
    "                # dash=\"dash\",  #<-- feature request: plotly/plotly.py#5443\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    .add_annotation(\n",
    "        ax=4.2,\n",
    "        ay=0.5,\n",
    "        x=5,\n",
    "        y=5.5,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        axref=\"x\",\n",
    "        ayref=\"y\",\n",
    "        text=\"Missing Data\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor=\"grey\",\n",
    "        bgcolor=\"white\",\n",
    "        standoff=30,\n",
    "        startstandoff=5,\n",
    "    )\n",
    "    .add_annotation(\n",
    "        ax=4.2,\n",
    "        ay=0.5,\n",
    "        x=5,\n",
    "        y=3,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        axref=\"x\",\n",
    "        ayref=\"y\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor=\"grey\",\n",
    "        standoff=30,\n",
    "        startstandoff=15,\n",
    "    )\n",
    "    .update_layout(\n",
    "        showlegend=False,\n",
    "        xaxis=dict(showgrid=False, showticklabels=False, showline=False, ticks=\"\"),\n",
    "        yaxis=dict(showgrid=False, showticklabels=False, showline=False, ticks=\"\"),\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"./images/00_extrapolation.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show(editable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ef666",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2be4a33b",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b01bd9",
   "metadata": {},
   "source": [
    "### Dropping\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Easy\n",
    "- Does not create 'fake' data\n",
    "- Preserves base statistics and correlation between variables\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Excessive data loss for multivariate data\n",
    "- Can create big gaps in your data\n",
    "- Not suitable if you already have a very small data set\n",
    "- Can cause sampling bias\n",
    "\n",
    "When to use:\n",
    "\n",
    "- Certain features are missing a large percentage of their data\n",
    "- There is a substantial structural change in the data, which is causing your models to become unstable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf9429",
   "metadata": {},
   "source": [
    "#### Dropping Observations\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>&nbsp;</td><td>&nbsp;</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Dropping the first<br>three rows<br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24725d0",
   "metadata": {},
   "source": [
    "#### Dropping Features\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>1.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Dropping the last<br>column <b>x2</b></b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befe829",
   "metadata": {},
   "source": [
    "### Recording\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Retains the models flexibility for how to fit the missing values\n",
    "- We can see the effect of the missing data in the estimated parameters\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- All missing values are assigned the same effect size in linear models (eg. ARIMA)\n",
    "- Not applicable for the target variable\n",
    "\n",
    "When to use:\n",
    "\n",
    "- You do not want data loss\n",
    "- Same effect size for all missing data is okay or the model is flexible enough to handle it (eg. tree-based models)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something<br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th><th>x1_m</th><th>x2_m</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\">0</td><td>1.2</td><td class=\"green\">1</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">0</td><td class=\"green\">0</td><td>1</td><td class=\"green\">1</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>16.4</td><td>0.8</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td class=\"green\">0</td><td>0.9</td><td class=\"green\">1</td><td class=\"green\">0</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td><td class=\"green\">0</td><td class=\"green\">0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2bea2",
   "metadata": {},
   "source": [
    "### Filling using Random Distribution\n",
    "\n",
    "Eg. random sample from a normal distribution created for the existing data in the specific feature.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Preserves the base statistics in the data set (mean, variances, etc)\n",
    "- Applicable also for target variables\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- But also preserves potential filter bias\n",
    "- Destroys correlation between variables\n",
    "- Model cannot distinguish real and imputed data\n",
    "\n",
    "When to use:\n",
    "\n",
    "- Other methods are not suitable in your circumstances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c456eb",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\">49.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">19.9</td><td class=\"green\">1.1</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">22.3</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6497b7d",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill ----\n",
    "nml: np.ndarray = np.random.default_rng(seed=42).normal(\n",
    "    loc=data[\"Missing\"].mean(),\n",
    "    scale=data[\"Missing\"].std(),\n",
    "    size=len(data),\n",
    ")\n",
    "data_random: pd.DataFrame = data.copy().assign(\n",
    "    Fill=lambda df: np.where(\n",
    "        df[\"Missing\"].isna(),\n",
    "        nml,\n",
    "        df[\"Missing\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f48da4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_random: float = mape(data_random[[\"Value\"]], data_random[[\"Fill\"]]) * 100\n",
    "plot_data(\n",
    "    data=data_random,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Random Distribution\",\n",
    "    subtitle=f\"MAPE={score_random:.2f}%\",\n",
    "    output_file=\"./images/01_filling_using_random_distribution.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbb501",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c10011",
   "metadata": {},
   "source": [
    "### Filling using Feed-Forward\n",
    "\n",
    "Eg. take the most recent value, and feed it forward to fill the gaps.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Easy\n",
    "- Often used as a naïve benchmark because it is super default\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Lacks any deeper logical understanding of the data\n",
    "- Does not account for trends or seasonality, etc\n",
    "\n",
    "When to use:\n",
    "\n",
    "- Good as a benchmark or dirty hack only\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\"><code>NaN</code></td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">14.4</td><td class=\"green\">0.7</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td class=\"green\">19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b73816",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill ----\n",
    "data_ffill: pd.DataFrame = data.assign(\n",
    "    Fill=lambda df: df[\"Missing\"].ffill(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c101e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_ffill: float = mape(data_ffill[[\"Value\"]], data_ffill[[\"Fill\"]]) * 100\n",
    "plot_data(\n",
    "    data=data_ffill,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Feed-Forward\",\n",
    "    subtitle=f\"MAPE={score_ffill:.2f}%\",\n",
    "    output_file=\"./images/02_filling_using_feed_forward.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe4a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ac43ca",
   "metadata": {},
   "source": [
    "### Filling using Imputation ($σ$ or $x~$)\n",
    "\n",
    "A statistical method of filling missing values which goes ideally beyond plain 'prediction' of the missing values. Imputation tries to preserve ALL statistical properties of the original (unknown) data, including means, variances, etc., including the noise level.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Easy to calculate and input mean (σ) or median (x~) values\n",
    "- Best option to create a filled dataset without any bias for arbitrary statistical analysis later on\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Inserted values are not close to the real ones\n",
    "- Reduction of sample variance\n",
    "- Complicated, no time-series specific solution is available\n",
    "- Not very common in machine learning, it is used more in the statistics domain\n",
    "\n",
    "When to use:\n",
    "\n",
    "- Other methods are not suitable in your circumstances\n",
    "- You don't know what kind of analysis will be done on the filled data set later\n",
    "- You look for a best-in-class solution for filling missing values\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\">23.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">23.2</td><td class=\"green\">1.0</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">23.2</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055b19d",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill ----\n",
    "data_stats: pd.DataFrame = data.assign(\n",
    "    Fill=lambda df: np.where(\n",
    "        df[\"Missing\"].isna(),\n",
    "        df[\"Missing\"].mean(),\n",
    "        df[\"Missing\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e8ab8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_stats: float = mape(data_stats[[\"Value\"]], data_stats[[\"Fill\"]]) * 100\n",
    "plot_data(\n",
    "    data=data_stats,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Imputation (average value)\",\n",
    "    subtitle=f\"MAPE={score_stats:.2f}%\",\n",
    "    output_file=\"./images/03_filling_using_imputation.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e9ae9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad9fa74d",
   "metadata": {},
   "source": [
    "### Filling using Interpolation\n",
    "\n",
    "Unlike statistical prediction (curve fitting), interpolation is a numerical method to overlay a curve into known variables (nodes) such that the curve hits the known values exactly and approximates what happens in between. This makes sense only if there is a continuous trend between the known nodes. You can use methods such as linear interpolation, polynomial, splines, etc.\n",
    "\n",
    "The difference between imputation and interpolation is that the latter does not try to preserve the statistical properties of the original data, but rather it is a mathematical approach to estimate the missing values based on the known ones (usually by creating a straight-line between known data points). Interpolation is univariate, meaning it only uses the values of the variable itself to estimate the missing values, without considering other variables, and it assumes continuity in the underlying data. Interpolation is used frequently in time series analysis to fill in gaps in data, especially when the data is expected to follow a certain trend or pattern over time.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Follows the local trend\n",
    "- Better than feed-forward\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Approach is univariate (that is, it does not take in to account exogeneous variables, like holiday information, etc)\n",
    "- Resembles a trend rather than a seasonality or autocorrelation\n",
    "\n",
    "When to use:\n",
    "\n",
    "- You want something not extremely trivial, but is still readily available. For example, Pandas has this method already implemented.\n",
    "- A good trend fit seems most important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbb9cb",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>&nbsp;</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td class=\"green\">31</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td class=\"green\">2.0</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td class=\"green\">1.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>20.1</td><td class=\"green\">1.4</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td class=\"green\">19.3</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">19.7</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757561b3",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c892684",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill ----\n",
    "data_interpolation: pd.DataFrame = data.assign(\n",
    "    Fill=lambda df: df[\"Missing\"].interpolate(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0067c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_interpolation: float = mape(data_interpolation[[\"Value\"]], data_interpolation[[\"Fill\"]]) * 100\n",
    "plot_data(\n",
    "    data=data_interpolation,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Interpolation\",\n",
    "    subtitle=f\"MAPE={score_interpolation:.2f}%\",\n",
    "    output_file=\"./images/04_filling_using_interpolation.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1293b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64bdaa49",
   "metadata": {},
   "source": [
    "### Filling using Time-Series Prediction\n",
    "\n",
    "Eg. run a forecasting algorithm (like ARIMA) to 'predict' the missing future values.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Promises a better fit\n",
    "- Can better reconstruct non-random missingness\n",
    "- Applicable also for target variable\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Only useful if the time series is actually predictable\n",
    "- Don't forget the Münchhausen trilemma[^munchhausen-trilemma] of trying to create a forecast from predicted data\n",
    "- Predicted values are filled in 'without noise'; that is, without 'variance biase'\n",
    "\n",
    "When to use:\n",
    "\n",
    "- The variables have strong time series properties and strong correlations among each other so that the prediction approach is powerful and precise\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>&nbsp;</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>18.2</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">16.6</td><td class=\"green\">0.9</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td class=\"green\">9.3</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">19.7</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ac682",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill ----\n",
    "data_forecast: pd.DataFrame = data.copy().assign(Fill=data[\"Missing\"])\n",
    "indexes_of_missing: list[int] = data_forecast[data_forecast[\"Fill\"].isna()].index.to_list()\n",
    "for idx in tqdm(indexes_of_missing):\n",
    "    tmp: pd.DataFrame = data_forecast.loc[:idx]\n",
    "    fcst_values: np.ndarray = tmp[[\"Fill\"]].values[:-1]\n",
    "    tmp_modl = auto_arima(\n",
    "        fcst_values if len(fcst_values) > 2 else np.append(fcst_values[1], fcst_values),\n",
    "        random_state=RANDOM_SEED,\n",
    "        seasonal=True,\n",
    "        stepwise=True,\n",
    "        error_action=\"ignore\",\n",
    "    )\n",
    "    fcst = tmp_modl.predict(n_periods=1, return_conf_int=False)\n",
    "    data_forecast.loc[idx, \"Fill\"] = fcst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d65e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_forecast: float = mape(data_forecast[\"Value\"], data_forecast[\"Fill\"]) * 100\n",
    "plot_data(\n",
    "    data=data_forecast,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Time-Series Forecasting (ARIMA)\",\n",
    "    subtitle=f\"MAPE={score_forecast:.2f}%\",\n",
    "    output_file=\"./images/05_filling_using_arima_forecasting.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b5a7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1716bbe",
   "metadata": {},
   "source": [
    "### Filling using Algorithmic Prediction (Classification & Regression)\n",
    "\n",
    "Eg. run a prediction algorithm (whether it be a classification or regression problem) over missing data in the predictor features.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Promises a better fit\n",
    "- Can better reconstruct non-random missingness\n",
    "- Applicable also for target variable\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Münchhausen trilemma[^munchhausen-trilemma] also applies\n",
    "- Predicted values are filled in 'without noise'; that is, without 'variance biase'\n",
    "\n",
    "When to use:\n",
    "\n",
    "- Other methods are not suitable in your circumstances\n",
    "\n",
    "**The Core Problem**\n",
    "\n",
    "Classical ML algorithms like Random Forest, XGBoost, or Linear Regression treat each row as i.i.d. (independent and identically distributed). Time series violates this assumption because:\n",
    "\n",
    "- **Temporal autocorrelation**: Today's value depends on yesterday's\n",
    "- **Trend**: Values systematically increase/decrease over time\n",
    "- **Seasonality**: Patterns repeat at regular intervals\n",
    "- **Order matters**: Shuffling rows destroys information\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\">&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">&nbsp;</td><td class=\"green\">&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2edf3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ffaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    assert \"Date\" in df.columns, \"DataFrame must contain 'Date' column\"\n",
    "    tmp: pd.DataFrame = df.copy()\n",
    "    return tmp.assign(\n",
    "        Year=lambda df: df[\"Date\"].dt.year,\n",
    "        MonthOfYear=lambda df: df[\"Date\"].dt.month,\n",
    "        DayOfMonth=lambda df: df[\"Date\"].dt.day,\n",
    "        DayOfYear=lambda df: df[\"Date\"].dt.day_of_year,\n",
    "        DayOfWeek=lambda df: df[\"Date\"].dt.day_of_week + 1,\n",
    "        QuarterOfYear=lambda df: df[\"Date\"].dt.quarter,\n",
    "        IsWeekend=lambda df: df[\"Date\"].dt.dayofweek.isin([5, 6]).astype(int),\n",
    "        IsWeekday=lambda df: (~df[\"Date\"].dt.dayofweek.isin([5, 6])).astype(int),\n",
    "    ).drop(columns=[\"Date\"])\n",
    "\n",
    "\n",
    "def build_lag_features(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    tmp: pd.DataFrame = df.copy()\n",
    "    lags: list[int] = tmp.index.to_list()\n",
    "    return tmp.assign(**{f\"Lag_{lag}\": tmp[target_col].shift(lag) for lag in lags if lag != 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eb55cd",
   "metadata": {},
   "source": [
    "#### One at a Time\n",
    "\n",
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324781fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill, one record at a time ----\n",
    "\n",
    "# Partially create RandomForestRegressor\n",
    "RFR: partial[RandomForestRegressor] = partial(\n",
    "    RandomForestRegressor,\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# Reassign dataframe\n",
    "data_algorithmic_1: pd.DataFrame = data.copy().assign(Fill=data[\"Missing\"])\n",
    "\n",
    "# Identify indexes of missing values\n",
    "indexes_of_missing: list[int] = data_algorithmic_1[data_algorithmic_1[\"Fill\"].isna()].index.to_list()\n",
    "\n",
    "# Iterate over indexes of missing values\n",
    "for idx in tqdm(indexes_of_missing):\n",
    "\n",
    "    tmp_df: pd.DataFrame = (\n",
    "        # Assign temporary dataframe\n",
    "        data_algorithmic_1.copy()\n",
    "        # Drop unnecessary columns\n",
    "        .drop(columns=[\"index\", \"Value\", \"Missing\"])\n",
    "        # Filter table up until the index of the target missing value\n",
    "        .iloc[: idx + 1]\n",
    "        # Build temporal features\n",
    "        .pipe(build_temporal_features)\n",
    "        # Assign lag features\n",
    "        .pipe(build_lag_features, target_col=\"Fill\")\n",
    "    )\n",
    "\n",
    "    # Split data into train and test\n",
    "    data_trn_X: np.ndarray = tmp_df.drop(columns=[\"Fill\"]).iloc[:-1].values\n",
    "    data_trn_y: np.ndarray = tmp_df[[\"Fill\"]].iloc[:-1].values\n",
    "    data_tst_X: np.ndarray = tmp_df.drop(columns=[\"Fill\"]).iloc[-1:].values\n",
    "\n",
    "    # Instantiate, fit, predict model\n",
    "    pred: float = RFR().fit(data_trn_X, data_trn_y).predict(data_tst_X)[0]\n",
    "\n",
    "    # Assign prediction\n",
    "    data_algorithmic_1.loc[idx, \"Fill\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63f2cd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_algorithmic_1: float = mape(data_algorithmic_1[\"Value\"], data_algorithmic_1[\"Fill\"]) * 100\n",
    "plot_data(\n",
    "    data=data_algorithmic_1,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Machine Learning (Random Forest Regression)\",\n",
    "    subtitle=f\"MAPE={score_algorithmic_1:.2f}%\",\n",
    "    output_file=\"./images/06_filling_using_machine_learning_1.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd0069",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b872eb",
   "metadata": {},
   "source": [
    "#### All at Once\n",
    "\n",
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff33580",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do fill, all at once ----\n",
    "\n",
    "# Reassign dataframe\n",
    "data_algorithmic_2: pd.DataFrame = data.copy().assign(Fill=data[\"Missing\"])\n",
    "\n",
    "# Identify indexes of missing values\n",
    "indexes_of_missing: list[int] = data_algorithmic_2[data_algorithmic_2[\"Fill\"].isna()].index.to_list()\n",
    "indexes_of_existing: list[int] = data_algorithmic_2[data_algorithmic_2[\"Fill\"].notna()].index.to_list()\n",
    "\n",
    "# Partially create RandomForestRegressor\n",
    "RFR: partial[RandomForestRegressor] = partial(\n",
    "    RandomForestRegressor,\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "tmp_df: pd.DataFrame = (\n",
    "    # Assign temporary dataframe\n",
    "    data_algorithmic_2.copy()\n",
    "    # Drop unnecessary columns\n",
    "    .drop(columns=[\"index\", \"Value\", \"Missing\"])\n",
    "    # Build temporal features\n",
    "    .pipe(build_temporal_features)\n",
    "    # Assign lag features\n",
    "    .pipe(build_lag_features, target_col=\"Fill\")\n",
    ")\n",
    "\n",
    "# Split data into train and test\n",
    "data_trn_X: np.ndarray = tmp_df.drop(columns=[\"Fill\"]).iloc[indexes_of_existing, :].values\n",
    "data_trn_y: np.ndarray = tmp_df.loc[indexes_of_existing, [\"Fill\"]].values\n",
    "data_tst_X: np.ndarray = tmp_df.drop(columns=[\"Fill\"]).iloc[indexes_of_missing, :].values\n",
    "\n",
    "# Instantiate, fit, predict model\n",
    "pred: np.ndarray = RFR().fit(data_trn_X, data_trn_y).predict(data_tst_X)\n",
    "\n",
    "# Assign prediction\n",
    "data_algorithmic_2.loc[indexes_of_missing, \"Fill\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8f8de",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### Plot data ----\n",
    "score_algorithmic_2: float = mape(data_algorithmic_2[\"Value\"], data_algorithmic_2[\"Fill\"]) * 100\n",
    "plot_data(\n",
    "    data=data_algorithmic_2,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Machine Learning (Random Forest Regression)\",\n",
    "    subtitle=f\"MAPE={score_algorithmic_2:.2f}%\",\n",
    "    output_file=\"./images/06_filling_using_machine_learning_2.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52675c48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac699e0e",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Embedding methods are primarily used to remove noise and focus on the main information in the data. It can also be used to fill gaps just like de-noising, once the embedding has been identified. Can use generalised models like GLRM (Generalised Low Rank Models), or even autoencoders like MIDAS (Mixed Data Sampling).\n",
    "\n",
    "In this example, we use a **Denoising Autoencoder** to learn the underlying manifold of the data. The process involves:\n",
    "\n",
    "1.  **Data Preparation**: Scaling the data and filling missing values with a placeholder (e.g., -1) to allow input into the network.\n",
    "2.  **Architecture**: A neural network with an Encoder (compressing input to a lower-dimensional embedding) and a Decoder (reconstructing the original input).\n",
    "3.  **Training**: The model is trained on the complete records to learn the relationships between features.\n",
    "4.  **Imputation**: The model predicts (reconstructs) the missing values based on the learned patterns.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Strong for non-trivial, non-linear patterns\n",
    "- In particular when combined with multiple imputations\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Not very established method (compared to others mentioned)\n",
    "- Have to use specific packages to implement (e.g., TensorFlow/Keras)\n",
    "\n",
    "When to use:\n",
    "\n",
    "- You look for a best-in-class solution for filling missing values\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Source</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td>&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td>&nbsp;</td><td>&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td>&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\">Something</b><br>➡️</div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div class=\"center\"><b>Result</b></div>\n",
    "            <table>\n",
    "                <tr><th>t</th><th>y</th><th>x1</th><th>x2</th></tr>\n",
    "                <tr><td>2023-01-01</td><td>9.8</td><td class=\"green\">&nbsp;</td><td>1.2</td></tr>\n",
    "                <tr><td>2023-01-02</td><td>10.3</td><td>18.6</td><td>2.3</td></tr>\n",
    "                <tr><td>2023-01-03</td><td>24.6</td><td>49.2</td><td>0.5</td></tr>\n",
    "                <tr><td>2023-01-04</td><td>7.5</td><td>14.4</td><td>0.7</td></tr>\n",
    "                <tr><td>2023-01-05</td><td>11.1</td><td class=\"green\">&nbsp;</td><td class=\"green\">&nbsp;</td></tr>\n",
    "                <tr><td>2023-01-06</td><td>10.0</td><td>18.9</td><td>1.1</td></tr>\n",
    "                <tr><td>2023-01-07</td><td>9.9</td><td>19.1</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-08</td><td>8.7</td><td class=\"green\">&nbsp;</td><td>0.8</td></tr>\n",
    "                <tr><td>2023-01-09</td><td>10.6</td><td>20.1</td><td>0.9</td></tr>\n",
    "                <tr><td>2023-01-10</td><td>11.4</td><td>21.9</td><td>1.0</td></tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1ea5f",
   "metadata": {},
   "source": [
    "### No code\n",
    "\n",
    "### Show code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40247de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### Do fill using Autoencoder ----\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reassign dataframe\n",
    "data_embedding: pd.DataFrame = data.copy().assign(Fill=data[\"Missing\"])\n",
    "\n",
    "# Feature Engineering (reuse functions from previous section)\n",
    "tmp_df: pd.DataFrame = (\n",
    "    data_embedding.copy()\n",
    "    .drop(columns=[\"index\", \"Value\", \"Missing\"])\n",
    "    .pipe(build_temporal_features)\n",
    "    .pipe(build_lag_features, target_col=\"Fill\")\n",
    ")\n",
    "\n",
    "# Identify indexes\n",
    "indexes_of_missing: list[int] = data_embedding[data_embedding[\"Fill\"].isna()].index.to_list()\n",
    "indexes_of_existing: list[int] = data_embedding[data_embedding[\"Fill\"].notna()].index.to_list()\n",
    "\n",
    "# Prepare Data\n",
    "# Fill NaNs with a placeholder for scaling (though we train on existing)\n",
    "scaler = StandardScaler()\n",
    "tmp_df_filled = tmp_df.fillna(-1)\n",
    "X_scaled = scaler.fit_transform(tmp_df_filled)\n",
    "\n",
    "X_train = X_scaled[indexes_of_existing]\n",
    "X_missing = X_scaled[indexes_of_missing]\n",
    "\n",
    "# Define Model\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Encoder\n",
    "encoded = Dense(64, activation=\"relu\")(input_layer)\n",
    "encoded = LayerNormalization()(encoded)\n",
    "encoded = Dropout(0.2)(encoded)\n",
    "encoded = Dense(32, activation=\"relu\")(encoded)\n",
    "\n",
    "# Bottleneck\n",
    "embedding = Dense(16, activation=\"relu\", name=\"embedding\")(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(32, activation=\"relu\")(embedding)\n",
    "decoded = LayerNormalization()(decoded)\n",
    "decoded = Dropout(0.2)(decoded)\n",
    "decoded = Dense(64, activation=\"relu\")(decoded)\n",
    "\n",
    "# Output\n",
    "output_layer = Dense(input_dim, activation=\"linear\")(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "\n",
    "# Train\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, verbose=0)\n",
    "\n",
    "# Predict\n",
    "reconstructed = autoencoder.predict(X_missing)\n",
    "\n",
    "# Inverse Transform\n",
    "reconstructed_original = scaler.inverse_transform(reconstructed)\n",
    "\n",
    "# Assign\n",
    "fill_col_idx = tmp_df.columns.get_loc(\"Fill\")\n",
    "data_embedding.loc[indexes_of_missing, \"Fill\"] = reconstructed_original[:, fill_col_idx]\n",
    "\n",
    "### Plot data ----\n",
    "score_embedding: float = mape(data_embedding[\"Value\"], data_embedding[\"Fill\"]) * 100\n",
    "plot_data(\n",
    "    data=data_embedding,\n",
    "    date_col=\"Date\",\n",
    "    missing_col=\"Missing\",\n",
    "    fill_col=\"Fill\",\n",
    "    title=\"Filling using Autoencoder Embedding\",\n",
    "    subtitle=f\"MAPE={score_embedding:.2f}%\",\n",
    "    output_file=\"./images/07_filling_using_embedding.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476f164",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7130194",
   "metadata": {},
   "source": [
    "[^munchhausen-trilemma]: The Münchhausen trilemma asserts that there are only three ways of completing a proof; by circular argument, regressive argument, and dogmatic argument. Baron Münchhausen proposed a thought experiment where he tried to prove it was theoretically possible to free himself out of being stuck in the mud by pulling himself out with his own hair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e17fa",
   "metadata": {},
   "source": [
    "[`numpy`]: https://numpy.org/\n",
    "[`pandas`]: https://pandas.pydata.org/\n",
    "[`synthetic_data_generators`]: https://data-science-extensions.com/toolboxes/synthetic-data-generators/\n",
    "[`plotly`]: https://plotly.com/python/\n",
    "[`pmdarima`]: https://alkaline-ml.com/pmdarima/\n",
    "[`sklearn`]: https://scikit-learn.org/\n",
    "[`tqdm`]: https://tqdm.github.io/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
